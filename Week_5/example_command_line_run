python3 Spark_sql_script.py \
    --input_green=data/pq/green/2020/*/ \
    --input_yellow=data/pq/yellow/2020/*/ \
    --output=data/report/revenue-2020


URL="spark://de-zoomcamp-bb.us-east4-c.c.astral-volt-411512.internal:7077"

spark-submit \
    --master="${URL}" \
    Spark_sql_script.py \
        --input_green=data/pq/green/2021/*/ \
        --input_yellow=data/pq/yellow/2021/*/ \
        --output=data/report/revenue-2021


gcloud dataproc jobs submit pyspark \
>     --cluster=de-zoomcamp-cluster \
>     --region=us-east4 \
>     gs://week5batchspark/code/Spark_sql_script.py \
>     -- \
>         --input_green=gs://week5batchspark/pq/green/2020/*/ \
>         --input_yellow=gs://week5batchspark/pq/yellow/2020/*/ \
>         --output=gs://week5batchspark/report/revenue-2020

To copy file to bucket
gsutil cp Spark_sql_script_Big_Q.py gs://week5batchspark/code/

nytaxi.reports-2020

gcloud dataproc jobs submit pyspark \
     --cluster=de-zoomcamp-cluster \
     --region=us-east4 \
     --jars=gs://spark-lib/bigquery/spark-bigquery-with-dependencies_2.11-0.23.2.jar \
     gs://week5batchspark/code/Spark_sql_script_Big_Q.py \
     -- \
         --input_green=gs://week5batchspark/pq/green/2020/*/ \
         --input_yellow=gs://week5batchspark/pq/yellow/2020/*/ \
         --output=nytaxi.reports-2020